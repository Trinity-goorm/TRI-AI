{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dKZjz3k9xttS",
        "outputId": "8da9764b-e2f3-4362-ee6d-e2cba3576e0e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BxMJCImUxp68",
        "outputId": "2837d391-8c8c-4ff8-df13-de479f540c76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      id           name  category_id  score  review  \\\n",
            "0  00-01    이가네양꼬치 판교본점            0    4.0     570   \n",
            "1  00-02      동청담 삼평직영점            0    3.2      39   \n",
            "2  00-03         차알 판교점            0    2.9     690   \n",
            "3  00-04        몽중헌 판교점            0    3.7     356   \n",
            "4  00-05          최고집짬뽕            0    3.3      65   \n",
            "5  00-06          청계산수타            0    3.3      16   \n",
            "6  00-07  신승반점 현대백화점판교점            0    3.5     379   \n",
            "7  00-08         베이징스토리            0    2.6      51   \n",
            "8  00-09       마라공방 판교점            0    3.7     121   \n",
            "9  00-10      명품조박사짬뽕짜장            0    3.7      36   \n",
            "\n",
            "                                       address     operating_hour  \\\n",
            "0            경기 성남시 분당구 분당내곡로 155 KCC웰츠타워 104호   매일 12:00 ~ 24:00   \n",
            "1      경기 성남시 분당구 대왕판교로606번길 45 푸르지오시티 2층 206호   매일 15:00 ~ 17:00   \n",
            "2  경기 성남시 분당구 동판교로177번길 25 판교아비뉴프랑 2층 214-215호   매일 15:00 ~ 17:00   \n",
            "3              경기 성남시 분당구 분당내곡로 131 판교테크원타워 2층   매일 15:00 ~ 17:30   \n",
            "4                     경기 성남시 분당구 판교역로10번길 12-9   매일 15:30 ~ 16:30   \n",
            "5                     경기 성남시 분당구 판교공원로5길 22 1층   매일 10:40 ~ 21:00   \n",
            "6                 경기 성남시 분당구 판교역로146번길 20 지하1층  월~금 15:00 ~ 16:30   \n",
            "7      경기 성남시 분당구 판교역로 230 삼환하이펙스 B동 1층 120-1호  월~토 15:00 ~ 17:00   \n",
            "8     경기 성남시 분당구 판교역로192번길 12 판교미래에셋센터 2층 206호   매일 11:00 ~ 22:00   \n",
            "9                       경기 성남시 분당구 동판교로 153 1층   매일 10:00 ~ 22:00   \n",
            "\n",
            "   expanded_days open_time close_time  ...  conv_동물출입  conv_주차 conv_휠체어사용  \\\n",
            "0  월,화,수,목,금,토,일     12:00      24:00  ...          1        1          1   \n",
            "1  월,화,수,목,금,토,일     15:00      17:00  ...          0        1          0   \n",
            "2  월,화,수,목,금,토,일     15:00      17:00  ...          0        1          0   \n",
            "3  월,화,수,목,금,토,일     15:00      17:30  ...          1        1          0   \n",
            "4  월,화,수,목,금,토,일     15:30      16:30  ...          1        1          1   \n",
            "5  월,화,수,목,금,토,일     10:40      21:00  ...          0        1          0   \n",
            "6      월,화,수,목,금     15:00      16:30  ...          0        1          0   \n",
            "7    월,화,수,목,금,토     15:00      17:00  ...          1        1          1   \n",
            "8  월,화,수,목,금,토,일     11:00      22:00  ...          0        1          0   \n",
            "9  월,화,수,목,금,토,일     10:00      22:00  ...          0        1          0   \n",
            "\n",
            "  conv_흡연실 caution_배달가능 caution_배달불가 caution_예약가능  caution_예약불가  caution_포장가능  \\\n",
            "0        1            0            1            1             0             1   \n",
            "1        0            0            0            1             0             0   \n",
            "2        0            0            1            1             0             1   \n",
            "3        0            0            1            1             0             1   \n",
            "4        0            0            1            1             0             1   \n",
            "5        0            0            0            1             0             1   \n",
            "6        0            0            0            0             1             1   \n",
            "7        0            0            1            1             0             1   \n",
            "8        0            1            0            1             0             1   \n",
            "9        0            1            0            1             0             1   \n",
            "\n",
            "   caution_포장불가  \n",
            "0             0  \n",
            "1             0  \n",
            "2             0  \n",
            "3             0  \n",
            "4             0  \n",
            "5             0  \n",
            "6             0  \n",
            "7             0  \n",
            "8             0  \n",
            "9             0  \n",
            "\n",
            "[10 rows x 33 columns]\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "\n",
        "# 1. JSON 파일 로드\n",
        "json_path = '/content/drive/MyDrive/trinity_data/restaurants_data_prototype.json'\n",
        "with open(json_path, 'r', encoding='utf-8') as f:\n",
        "    data = json.load(f)\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# 2. 기본 컬럼 타입 변환\n",
        "# review: 숫자형으로 변환 (변환 실패 시 NaN)\n",
        "df['review'] = pd.to_numeric(df['review'], errors='coerce')\n",
        "\n",
        "# category_id: 정수형으로 변환 시도 (실패하면 원본 유지)\n",
        "# 한글 카테고리명을 원하는 숫자로 매핑하는 딕셔너리\n",
        "category_mapping = {\n",
        "    \"중식\": 0,\n",
        "    \"일식집\": 1,\n",
        "    \"브런치카페\": 2,\n",
        "    \"파스타\": 3,\n",
        "    \"이탈리안\": 4,\n",
        "    \"이자카야\": 5,\n",
        "    \"한식집\": 6,\n",
        "    \"치킨\": 7,\n",
        "    \"스테이크\": 8,\n",
        "    \"고깃집\": 9,\n",
        "    \"다이닝바\": 10,\n",
        "    \"오마카세\": 11\n",
        "}\n",
        "\n",
        "def convert_category(cat):\n",
        "    # 먼저 매핑 딕셔너리를 통해 변환 시도\n",
        "    if cat in category_mapping:\n",
        "        return category_mapping[cat]\n",
        "    else:\n",
        "        try:\n",
        "            return int(cat)\n",
        "        except:\n",
        "            return cat\n",
        "\n",
        "df['category_id'] = df['category_id'].apply(convert_category)\n",
        "\n",
        "\n",
        "# phone_number: 숫자형(또는 실수)일 경우 정수 변환 후 문자열로 변경\n",
        "def format_phone(num):\n",
        "    if pd.isna(num):\n",
        "        return \"\"\n",
        "    try:\n",
        "        num_int = int(num)\n",
        "        return str(num_int)\n",
        "    except:\n",
        "        return str(num)\n",
        "df['phone_number'] = df['phone_number'].apply(format_phone)\n",
        "\n",
        "# 3. 편의시설(convenience) 처리 및 인코딩\n",
        "# 원본 편의시설 컬럼은 그대로 유지합니다.\n",
        "convenience_counter = Counter()\n",
        "def normalize_convenience(val):\n",
        "    items = val.split('\\n')\n",
        "    normalized_items = []\n",
        "    for item in items:\n",
        "        normalized_item = item.strip()\n",
        "        if normalized_item == \"정보 없음\":\n",
        "            normalized_item = \"편의시설 정보 없음\"\n",
        "        normalized_items.append(normalized_item)\n",
        "        convenience_counter[normalized_item] += 1\n",
        "    return normalized_items\n",
        "\n",
        "# 결측치는 빈 문자열(\"\")로 처리한 후 리스트 생성\n",
        "df['convenience_list'] = df['convenience'].fillna(\"\").apply(lambda x: normalize_convenience(x) if x != \"\" else [])\n",
        "\n",
        "# 다중 원-핫 인코딩 (MultiLabelBinarizer)\n",
        "mlb_conv = MultiLabelBinarizer()\n",
        "conv_encoded = mlb_conv.fit_transform(df['convenience_list'])\n",
        "conv_encoded_df = pd.DataFrame(conv_encoded,\n",
        "                               columns=[f\"conv_{col}\" for col in mlb_conv.classes_],\n",
        "                               index=df.index)\n",
        "\n",
        "# 4. 유의사항(caution) 처리 및 인코딩\n",
        "caution_counter = Counter()\n",
        "def normalize_caution(val):\n",
        "    items = val.split(',')\n",
        "    normalized_items = []\n",
        "    for item in items:\n",
        "        normalized_item = item.strip()\n",
        "        if normalized_item == \"정보 없음\":\n",
        "            normalized_item = \"유의사항 정보 없음\"\n",
        "        normalized_items.append(normalized_item)\n",
        "        caution_counter[normalized_item] += 1\n",
        "    return normalized_items\n",
        "\n",
        "df['caution_list'] = df['caution'].fillna(\"\").apply(lambda x: normalize_caution(x) if x != \"\" else [])\n",
        "mlb_caution = MultiLabelBinarizer()\n",
        "caution_encoded = mlb_caution.fit_transform(df['caution_list'])\n",
        "caution_encoded_df = pd.DataFrame(caution_encoded,\n",
        "                                  columns=[f\"caution_{col}\" for col in mlb_caution.classes_],\n",
        "                                  index=df.index)\n",
        "\n",
        "# 5. expanded_days를 이용한 operating_days_count 계산\n",
        "def count_operating_days(expanded_days):\n",
        "    day_order = [\"월\", \"화\", \"수\", \"목\", \"금\", \"토\", \"일\"]\n",
        "    if not isinstance(expanded_days, str) or expanded_days.strip() == \"\":\n",
        "        return None\n",
        "    expanded_days = expanded_days.strip()\n",
        "    if \"~\" in expanded_days:\n",
        "        parts = expanded_days.split(\"~\")\n",
        "        if len(parts) != 2:\n",
        "            return None\n",
        "        start = parts[0].strip()\n",
        "        end = parts[1].strip()\n",
        "        if start in day_order and end in day_order:\n",
        "            start_idx = day_order.index(start)\n",
        "            end_idx = day_order.index(end)\n",
        "            if start_idx <= end_idx:\n",
        "                return end_idx - start_idx + 1\n",
        "            else:\n",
        "                # wrap-around (예: \"토~화\")\n",
        "                return (7 - start_idx) + (end_idx + 1)\n",
        "        else:\n",
        "            return None\n",
        "    else:\n",
        "        days = [d.strip() for d in expanded_days.split(\",\") if d.strip() != \"\"]\n",
        "        return len(days)\n",
        "df['operating_days_count'] = df['expanded_days'].apply(lambda x: count_operating_days(x) if pd.notna(x) else None)\n",
        "\n",
        "# 6. time_range 처리: open_time, close_time 추출\n",
        "df['open_time'] = df['time_range'].apply(lambda x: x.split(\" ~ \")[0] if isinstance(x, str) and \" ~ \" in x else None)\n",
        "df['close_time'] = df['time_range'].apply(lambda x: x.split(\" ~ \")[1] if isinstance(x, str) and \" ~ \" in x else None)\n",
        "\n",
        "# 시간 문자열(\"HH:MM\")을 분으로 변환하는 함수 (특히 \"24:00\"은 1440분으로 처리)\n",
        "def convert_to_minutes(time_str):\n",
        "    if not time_str:\n",
        "        return None\n",
        "    if time_str == \"24:00\":\n",
        "        return 1440\n",
        "    try:\n",
        "        h, m = map(int, time_str.split(\":\"))\n",
        "        return h * 60 + m\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "df['open_minutes'] = df['open_time'].apply(convert_to_minutes)\n",
        "df['close_minutes'] = df['close_time'].apply(convert_to_minutes)\n",
        "\n",
        "# 영업시간(분) 및 시간 단위 계산\n",
        "def compute_duration(row):\n",
        "    if pd.isna(row['open_minutes']) or pd.isna(row['close_minutes']):\n",
        "        return None\n",
        "    open_m = row['open_minutes']\n",
        "    close_m = row['close_minutes']\n",
        "    if close_m >= open_m:\n",
        "        return close_m - open_m\n",
        "    else:\n",
        "        return (24 * 60 - open_m) + close_m\n",
        "\n",
        "df['duration'] = df.apply(compute_duration, axis=1)\n",
        "df['duration_hours'] = df['duration'] / 60.0\n",
        "\n",
        "# 7. open_hour, close_hour 계산\n",
        "# open_hour: open_time의 시(hour) 부분, close_hour: close_time의 시(hour) (단, \"24:00\"이면 null 처리)\n",
        "df['open_hour'] = df['open_time'].apply(lambda x: float(x.split(\":\")[0]) if x and \":\" in x else None)\n",
        "df['close_hour'] = df['close_time'].apply(lambda x: None if x == \"24:00\" else (float(x.split(\":\")[0]) if x and \":\" in x else None))\n",
        "\n",
        "# 8. 인코딩된 편의시설, 유의사항 컬럼 병합\n",
        "df = pd.concat([df, conv_encoded_df, caution_encoded_df], axis=1)\n",
        "\n",
        "# 인코딩 후 불필요한 리스트 컬럼 제거\n",
        "df.drop(columns=['convenience_list', 'caution_list'], inplace=True)\n",
        "\n",
        "# 9. 최종 출력할 컬럼만 선택\n",
        "final_columns = [\n",
        "    \"id\", \"name\", \"category_id\", \"score\", \"review\", \"address\",\n",
        "    \"operating_hour\", \"expanded_days\", \"open_time\", \"close_time\",\n",
        "    \"duration\", \"duration_hours\", \"time_range\", \"phone_number\",\n",
        "    \"image_urls\", \"convenience\", \"caution\", \"is_deleted\",\n",
        "    \"operating_days_count\", \"open_hour\", \"close_hour\"\n",
        "]\n",
        "\n",
        "# 인코딩된 편의시설 컬럼 (접두어 conv_)와 유의사항 컬럼 (접두어 caution_) 추가\n",
        "# 단, \"conv_편의시설 정보 없음\"과 \"caution_유의사항 정보 없음\"은 제외합니다.\n",
        "conv_cols = [col for col in df.columns if col.startswith(\"conv_\") and col != \"conv_편의시설 정보 없음\"]\n",
        "caution_cols = [col for col in df.columns if col.startswith(\"caution_\") and col != \"caution_유의사항 정보 없음\"]\n",
        "\n",
        "final_columns += conv_cols + caution_cols\n",
        "\n",
        "df_final = df[final_columns]\n",
        "\n",
        "# 최종 결과 확인 (원하는 순서의 컬럼만 존재)\n",
        "print(df_final.head(10))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PB3pYZo0RdLe",
        "outputId": "fbf33111-0b20-4b53-e23e-acea6dc3c9fc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: catboost in /usr/local/lib/python3.11/dist-packages (1.2.7)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from catboost) (3.10.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from catboost) (1.26.4)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.11/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from catboost) (1.13.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (3.2.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly->catboost) (9.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
      ],
      "metadata": {
        "id": "fZ9VpKP2Rhij"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files  # Colab 환경에서 파일 다운로드를 위해\n",
        "\n",
        "# Scikit-learn 및 관련 라이브러리 임포트\n",
        "from sklearn.experimental import enable_iterative_imputer  # 반드시 import 필요\n",
        "from sklearn.impute import IterativeImputer, KNNImputer\n",
        "from sklearn.linear_model import Ridge, BayesianRidge\n",
        "from sklearn.ensemble import RandomForestRegressor, StackingRegressor\n",
        "from xgboost import XGBRegressor\n",
        "import lightgbm as lgb\n",
        "from catboost import CatBoostRegressor\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "\n",
        "#####################################\n",
        "# 사용자 정의 추천 보정 가중치 (조정 가능, 올리면 영향력이 커지고, 내리면 작아짐)\n",
        "#####################################\n",
        "\n",
        "# 이 값은 리뷰 수나 리뷰 점수(로그 변환된 값 등)가 최종 평점에 얼마나 큰 영향을 줄지를 결정, 기존 0.1보다 약간 높임\n",
        "review_weight = 0.4\n",
        "\n",
        "# 이 값은 유의사항(positive, negative caution 항목들: 예를 들어 \"예약가능\", \"포장가능\" 등 긍정적인 항목과 \"예약불가\", \"배달불가\" 등 부정적인 항목)의 차이가 최종 평점에 미치는 영향, 기존 0.2보다 약간 낮춤\n",
        "caution_weight = 0.15\n",
        "\n",
        "# 편의시설 컬럼들은 one-hot 인코딩되어 각 식당에 대해 해당 편의시설이 있으면 1, 없으면 0\n",
        "convenience_weight = 0.15  # 편의시설 보정 가중치\n",
        "\n",
        "#####################################\n",
        "# 1. 데이터 로드 및 기본 전처리\n",
        "#####################################\n",
        "# 전처리된 DataFrame인 df_final을 바로 사용\n",
        "data = df_final.copy()\n",
        "\n",
        "# 필수 컬럼: duration_hours, conv_WIFI, conv_주차, caution_예약가능, category_id\n",
        "required_cols = ['duration_hours', 'conv_WIFI', 'conv_주차', 'caution_예약가능', 'category_id']\n",
        "data.dropna(subset=required_cols, inplace=True)\n",
        "\n",
        "# 도메인 규칙:\n",
        "# 평점을 제공하지 않은 식당은 score가 0으로 기록되어 있다고 가정.\n",
        "# 만약 score와 review가 모두 0이면, 평점 미제공으로 간주하여 score를 NaN으로 처리.\n",
        "data.loc[(data['score'] == 0) & (data['review'] == 0), 'score'] = np.nan\n",
        "\n",
        "# indicator: 평점을 제공했는지 여부\n",
        "data['score_provided'] = data['score'].notna().astype(int)\n",
        "\n",
        "#####################################\n",
        "# 2. Imputation: 결측치 보완 (가상 평점 산출)\n",
        "#####################################\n",
        "impute_cols = ['score', 'review']\n",
        "imputer = IterativeImputer(estimator=BayesianRidge(), random_state=42, max_iter=10, initial_strategy='median')\n",
        "data[impute_cols] = imputer.fit_transform(data[impute_cols])\n",
        "# 도메인 최대 평점 5.0으로 클리핑\n",
        "data.loc[data['score'] > 5, 'score'] = 5.0\n",
        "\n",
        "#####################################\n",
        "# 3. 사용자 입력 및 선호 카테고리 필터링\n",
        "#####################################\n",
        "user_id = input(\"사용자 ID를 입력하세요: \")\n",
        "\n",
        "preferred_categories_input = input(\"선호하는 식당 카테고리 이름(최대 3개, 콤마로 구분)을 입력하세요: \")\n",
        "preferred_categories_list = [cat.strip() for cat in preferred_categories_input.split(\",\")][:3]\n",
        "\n",
        "category_mapping = {\n",
        "    \"중식\": 0, \"일식\": 1, \"브런치\": 2, \"파스타\": 3, \"이탈리안\": 4,\n",
        "    \"이자카야\": 5, \"한식\": 6, \"치킨\": 7, \"스테이크\": 8,\n",
        "    \"고깃집\": 9, \"다이닝바\": 10, \"오마카세\": 11\n",
        "}\n",
        "preferred_category_ids = [category_mapping[cat] for cat in preferred_categories_list if cat in category_mapping]\n",
        "\n",
        "if not preferred_category_ids:\n",
        "    print(\"유효한 카테고리 입력이 없어 프로그램을 종료합니다.\")\n",
        "    exit()\n",
        "\n",
        "data_filtered = data[data['category_id'].isin(preferred_category_ids)].copy()\n",
        "if data_filtered.empty:\n",
        "    print(\"해당 선호 카테고리에 해당하는 식당 데이터가 없습니다.\")\n",
        "    exit()\n",
        "\n",
        "#####################################\n",
        "# 4. 피처 엔지니어링: 비선형 변환 및 상호작용 피처 추가\n",
        "#####################################\n",
        "# 기존 피처: ['review', 'duration_hours', 'conv_WIFI', 'conv_주차', 'caution_예약가능']\n",
        "# 추가 피처: 로그 변환된 review와 review와 duration_hours의 상호작용\n",
        "data_filtered['log_review'] = np.log(data_filtered['review'] + 1)\n",
        "data_filtered['review_duration'] = data_filtered['review'] * data_filtered['duration_hours']\n",
        "\n",
        "# 최종 모델 피처 목록에 기존 피처와 새로 만든 피처 포함\n",
        "model_features = ['review', 'duration_hours', 'conv_WIFI', 'conv_주차', 'caution_예약가능', 'log_review', 'review_duration']\n",
        "target = 'score'\n",
        "\n",
        "X_all = data_filtered[model_features].copy()\n",
        "y_all = data_filtered[target]\n",
        "\n",
        "#####################################\n",
        "# 5. 특성 스케일링 및 데이터 분할\n",
        "#####################################\n",
        "scaler = StandardScaler()\n",
        "X_all_scaled = scaler.fit_transform(X_all)\n",
        "X_train_all, X_test_all, y_train_all, y_test_all = train_test_split(X_all_scaled, y_all, test_size=0.2, random_state=42)\n",
        "\n",
        "#####################################\n",
        "# 6. 모델 학습 및 하이퍼파라미터 튜닝 (cv=3, 축소된 범위)\n",
        "#####################################\n",
        "# Model 1: Ridge\n",
        "param_grid_ridge = {'alpha': [0.0001, 0.001, 0.01, 0.1, 1, 10]}\n",
        "ridge = Ridge()\n",
        "grid_search_ridge = GridSearchCV(ridge, param_grid_ridge, cv=3, scoring='r2')\n",
        "grid_search_ridge.fit(X_train_all, y_train_all)\n",
        "best_ridge = grid_search_ridge.best_estimator_\n",
        "\n",
        "# Model 2: RandomForest\n",
        "rf = RandomForestRegressor(random_state=42)\n",
        "param_grid_rf = {\n",
        "    'n_estimators': [50, 100],\n",
        "    'max_depth': [None, 5, 10],\n",
        "    'min_samples_split': [2, 5]\n",
        "}\n",
        "grid_search_rf = GridSearchCV(rf, param_grid_rf, cv=3, scoring='r2')\n",
        "grid_search_rf.fit(X_train_all, y_train_all)\n",
        "best_rf = grid_search_rf.best_estimator_\n",
        "\n",
        "# Model 3: XGBoost\n",
        "xgb_model = XGBRegressor(objective='reg:squarederror', random_state=42)\n",
        "param_grid_xgb = {\n",
        "    'n_estimators': [50, 100],\n",
        "    'max_depth': [3, 5],\n",
        "    'learning_rate': [0.01, 0.1]\n",
        "}\n",
        "grid_search_xgb = GridSearchCV(xgb_model, param_grid_xgb, cv=3, scoring='r2')\n",
        "grid_search_xgb.fit(X_train_all, y_train_all)\n",
        "best_xgb = grid_search_xgb.best_estimator_\n",
        "\n",
        "# Model 4: LightGBM\n",
        "lgb_model = lgb.LGBMRegressor(random_state=42, verbose=-1, min_split_gain=0)\n",
        "param_grid_lgb = {\n",
        "    'n_estimators': [50, 100],\n",
        "    'max_depth': [3, 5, 7, -1],\n",
        "    'learning_rate': [0.01, 0.1]\n",
        "}\n",
        "grid_search_lgb = GridSearchCV(lgb_model, param_grid_lgb, cv=3, scoring='r2')\n",
        "grid_search_lgb.fit(X_train_all, y_train_all)\n",
        "best_lgb = grid_search_lgb.best_estimator_\n",
        "\n",
        "# Model 5: CatBoost\n",
        "cat_model = CatBoostRegressor(random_state=42, verbose=0)\n",
        "param_grid_cat = {\n",
        "    'iterations': [50, 100],\n",
        "    'depth': [3, 5],\n",
        "    'learning_rate': [0.01, 0.1]\n",
        "}\n",
        "grid_search_cat = GridSearchCV(cat_model, param_grid_cat, cv=3, scoring='r2')\n",
        "grid_search_cat.fit(X_train_all, y_train_all)\n",
        "best_cat = grid_search_cat.best_estimator_\n",
        "\n",
        "# Model 6: MLPRegressor\n",
        "# lbfgs (솔버) - 소규모 데이터셋일 경우 사용\n",
        "mlp = MLPRegressor(random_state=42, max_iter=1500, early_stopping=True, tol=1e-3)\n",
        "param_grid_mlp = {\n",
        "    'hidden_layer_sizes': [(50,), (100,)],\n",
        "    'alpha': [0.0001, 0.001]\n",
        "}\n",
        "grid_search_mlp = GridSearchCV(mlp, param_grid_mlp, cv=3, scoring='r2')\n",
        "grid_search_mlp.fit(X_train_all, y_train_all)\n",
        "best_mlp = grid_search_mlp.best_estimator_\n",
        "\n",
        "# 개별 모델 CV R² 계산\n",
        "cv_ridge = cross_val_score(best_ridge, X_train_all, y_train_all, cv=3, scoring='r2').mean()\n",
        "cv_rf = cross_val_score(best_rf, X_train_all, y_train_all, cv=3, scoring='r2').mean()\n",
        "cv_xgb = cross_val_score(best_xgb, X_train_all, y_train_all, cv=3, scoring='r2').mean()\n",
        "cv_lgb = cross_val_score(best_lgb, X_train_all, y_train_all, cv=3, scoring='r2').mean()\n",
        "cv_cat = cross_val_score(best_cat, X_train_all, y_train_all, cv=3, scoring='r2').mean()\n",
        "cv_mlp = cross_val_score(best_mlp, X_train_all, y_train_all, cv=3, scoring='r2').mean()\n",
        "\n",
        "print(\"개별 모델 CV R²:\")\n",
        "print(\"Ridge:\", cv_ridge)\n",
        "print(\"RandomForest:\", cv_rf)\n",
        "print(\"XGBoost:\", cv_xgb)\n",
        "print(\"LightGBM:\", cv_lgb)\n",
        "print(\"CatBoost:\", cv_cat)\n",
        "print(\"MLPRegressor:\", cv_mlp)\n",
        "\n",
        "# 앙상블: StackingRegressor (베이스: 모든 모델, 메타: Ridge)\n",
        "estimators = [\n",
        "    ('ridge', best_ridge),\n",
        "    ('rf', best_rf),\n",
        "    ('xgb', best_xgb),\n",
        "    ('lgb', best_lgb),\n",
        "    ('cat', best_cat),\n",
        "    ('mlp', best_mlp)\n",
        "]\n",
        "stacking_reg = StackingRegressor(\n",
        "    estimators=estimators,\n",
        "    final_estimator=Ridge(),\n",
        "    cv=3,\n",
        "    n_jobs=-1\n",
        ")\n",
        "stacking_reg.fit(X_train_all, y_train_all)\n",
        "cv_stacking = cross_val_score(stacking_reg, X_train_all, y_train_all, cv=3, scoring='r2').mean()\n",
        "print(\"Stacking 앙상블 CV R²:\", cv_stacking)\n",
        "\n",
        "#####################################\n",
        "# 7. 평가 지표 계산 (테스트 데이터)\n",
        "#####################################\n",
        "def evaluate_model(model, X, y):\n",
        "    y_pred = model.predict(X)\n",
        "    r2 = r2_score(y, y_pred)\n",
        "    rmse = np.sqrt(mean_squared_error(y, y_pred))\n",
        "    mae = mean_absolute_error(y, y_pred)\n",
        "    return r2, rmse, mae\n",
        "\n",
        "models = {\n",
        "    \"Ridge\": best_ridge,\n",
        "    \"RandomForest\": best_rf,\n",
        "    \"XGBoost\": best_xgb,\n",
        "    \"LightGBM\": best_lgb,\n",
        "    \"CatBoost\": best_cat,\n",
        "    \"MLPRegressor\": best_mlp,\n",
        "    \"Stacking\": stacking_reg\n",
        "}\n",
        "\n",
        "for name, model in models.items():\n",
        "    r2_val, rmse_val, mae_val = evaluate_model(model, X_test_all, y_test_all)\n",
        "    print(f\"\\n{name} 모델 평가:\")\n",
        "    print(f\"R²: {r2_val:.4f}\")\n",
        "    print(f\"RMSE: {rmse_val:.4f}\")\n",
        "    print(f\"MAE: {mae_val:.4f}\")\n",
        "\n",
        "#####################################\n",
        "# 8. 최종 추천: Stacking 앙상블 모델 사용 (전체 데이터 기반 추천)\n",
        "#####################################\n",
        "data_filtered = data_filtered.reset_index(drop=True)\n",
        "data_filtered['predicted_score'] = stacking_reg.predict(X_all_scaled)\n",
        "data_filtered['final_score'] = data_filtered['score']  # imputation 후 값 사용\n",
        "\n",
        "# 추가 보정: composite_score 산출 (리뷰와 유의사항 보정)\n",
        "for col in ['caution_배달가능', 'caution_예약가능', 'caution_포장가능',\n",
        "            'caution_배달불가', 'caution_예약불가', 'caution_포장불가']:\n",
        "    if col not in data_filtered.columns:\n",
        "        data_filtered[col] = 0\n",
        "\n",
        "# 'review' 컬럼을 숫자형으로 변환 (문자열이 있을 경우 처리)\n",
        "data_filtered['review'] = pd.to_numeric(data_filtered['review'], errors='coerce')\n",
        "\n",
        "def compute_composite_score(row, review_weight=review_weight, caution_weight=caution_weight, convenience_weight=convenience_weight):\n",
        "    base = row['final_score']\n",
        "\n",
        "    # 1. 리뷰 보정 로직 수정\n",
        "    review_val = float(row['review'])\n",
        "    # 리뷰 수가 적더라도 어느 정도 보정값을 받을 수 있도록 조정\n",
        "    review_adjust = review_weight * (np.log(review_val + 50) / np.log(1000))\n",
        "\n",
        "    # 2. 유의사항 보정 로직 강화\n",
        "    pos = row.get('caution_배달가능', 0) + row.get('caution_예약가능', 0) + row.get('caution_포장가능', 0)\n",
        "    neg = row.get('caution_배달불가', 0) + row.get('caution_예약불가', 0) + row.get('caution_포장불가', 0)\n",
        "\n",
        "    # 편의시설 보정: \"conv_\"로 시작하는 컬럼 중 \"conv_편의시설 정보 없음\"은 제외\n",
        "    conv_cols = [col for col in row.index if col.startswith(\"conv_\") and col != \"conv_편의시설 정보 없음\"]\n",
        "    if conv_cols and any(row[col] for col in conv_cols):\n",
        "        conv_mean = np.mean([row[col] for col in conv_cols])\n",
        "    else:\n",
        "        conv_mean = 0\n",
        "    conv_adjust = convenience_weight * conv_mean\n",
        "\n",
        "    return base + review_adjust + caution_weight * (pos - neg) + conv_adjust\n",
        "\n",
        "# 먼저 composite_score 계산\n",
        "data_filtered['composite_score'] = data_filtered.apply(compute_composite_score, axis=1)\n",
        "\n",
        "# sigmoid 함수 a와 b 값을 설정 (예: a=1.25, b=2.5 또는 원하는 값)\n",
        "a = 1.25\n",
        "b = 2.5\n",
        "\n",
        "# Sigmoid 변환 함수도 수정\n",
        "def sigmoid_transform(x, a, b):  # b값을 평균에 가깝게 조정\n",
        "    return 5 * (1 / (1 + np.exp(-a * (x - b))))\n",
        "\n",
        "# composite_score에 sigmoid 변환 적용\n",
        "data_filtered['composite_score'] = data_filtered['composite_score'].apply(lambda x: sigmoid_transform(x, a, b))\n",
        "\n",
        "# 최종 추천: composite_score 기준 내림차순 정렬\n",
        "recommendations_all = data_filtered.sort_values(by='composite_score', ascending=False)\n",
        "# 최종 추천 결과 출력 (예: id 컬럼 추가)\n",
        "print(\"\\n[전체 데이터 기반 추천] 상위 15개:\")\n",
        "print(recommendations_all[['id', 'category_id', 'score', 'predicted_score', 'composite_score']].head(15))\n",
        "\n",
        "# 상위 15개 결과 추출 (DataFrame recommendations_all이 이미 존재한다고 가정)\n",
        "top15 = recommendations_all[['id', 'category_id', 'score', 'predicted_score', 'composite_score']].head(15).copy()\n",
        "\n",
        "# predicted_score와 composite_score를 소수점 3자리까지 반올림\n",
        "top15['predicted_score'] = top15['predicted_score'].round(3)\n",
        "top15['composite_score'] = top15['composite_score'].round(3)\n",
        "\n",
        "# 사용자 정보와 추천 결과를 딕셔너리로 구성\n",
        "result_dict = {\n",
        "    \"user\": user_id,  # 앞에서 입력받은 사용자 ID\n",
        "    \"recommendations\": json.loads(top15.to_json(orient='records', force_ascii=False))\n",
        "}\n",
        "\n",
        "# 딕셔너리를 JSON 문자열로 변환 (들여쓰기 적용)\n",
        "result_json = json.dumps(result_dict, ensure_ascii=False, indent=4)\n",
        "\n",
        "# JSON 문자열 출력\n",
        "print(result_json)\n",
        "\n",
        "# JSON 파일로 저장 및 Colab 환경에서 다운로드\n",
        "with open('/content/recommendations_top15.json', 'w', encoding='utf-8') as f:\n",
        "    f.write(result_json)\n",
        "\n",
        "files.download('/content/recommendations_top15.json')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "gTU79RgKRSXa",
        "outputId": "9fe6783f-7bb7-426a-df1e-7f8c9034f23a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "사용자 ID를 입력하세요: toby\n",
            "선호하는 식당 카테고리 이름(최대 3개, 콤마로 구분)을 입력하세요: 다이닝바, 오마카세, 파스타\n",
            "개별 모델 CV R²:\n",
            "Ridge: -0.012135754288020606\n",
            "RandomForest: -0.13924784785179875\n",
            "XGBoost: -0.06318262950556501\n",
            "LightGBM: -0.045066674290735964\n",
            "CatBoost: -0.03886799752386735\n",
            "MLPRegressor: -0.4122050285959106\n",
            "Stacking 앙상블 CV R²: 0.009343805111709994\n",
            "\n",
            "Ridge 모델 평가:\n",
            "R²: 0.0290\n",
            "RMSE: 1.1561\n",
            "MAE: 0.7759\n",
            "\n",
            "RandomForest 모델 평가:\n",
            "R²: 0.0353\n",
            "RMSE: 1.1524\n",
            "MAE: 0.7801\n",
            "\n",
            "XGBoost 모델 평가:\n",
            "R²: 0.0186\n",
            "RMSE: 1.1623\n",
            "MAE: 0.7826\n",
            "\n",
            "LightGBM 모델 평가:\n",
            "R²: 0.0602\n",
            "RMSE: 1.1374\n",
            "MAE: 0.7754\n",
            "\n",
            "CatBoost 모델 평가:\n",
            "R²: 0.0437\n",
            "RMSE: 1.1473\n",
            "MAE: 0.7765\n",
            "\n",
            "MLPRegressor 모델 평가:\n",
            "R²: -0.0471\n",
            "RMSE: 1.2006\n",
            "MAE: 0.8429\n",
            "\n",
            "Stacking 모델 평가:\n",
            "R²: 0.0380\n",
            "RMSE: 1.1508\n",
            "MAE: 0.7673\n",
            "\n",
            "[전체 데이터 기반 추천] 상위 15개:\n",
            "         id  category_id  score  predicted_score  composite_score\n",
            "167  03-194            3    5.0         3.705841         4.920393\n",
            "94   03-102            3    5.0         3.833391         4.919741\n",
            "75    03-82            3    5.0         3.781578         4.918214\n",
            "150  03-172            3    4.9         3.976144         4.915888\n",
            "20    03-21            3    4.9         4.043883         4.913633\n",
            "120  03-132            3    5.0         3.790114         4.898242\n",
            "25    03-27            3    4.8         3.760449         4.889085\n",
            "102  03-111            3    5.0         3.807966         4.888933\n",
            "223   10-37           10    5.0         3.956887         4.885522\n",
            "188   11-21           11    5.0         3.716325         4.880219\n",
            "99   03-108            3    5.0         3.793507         4.870986\n",
            "238   10-67           10    5.0         3.744288         4.870635\n",
            "89    03-96            3    5.0         3.898539         4.868486\n",
            "16    03-17            3    5.0         3.990881         4.864038\n",
            "101  03-110            3    5.0         4.037500         4.858636\n",
            "{\n",
            "    \"user\": \"toby\",\n",
            "    \"recommendations\": [\n",
            "        {\n",
            "            \"id\": \"03-194\",\n",
            "            \"category_id\": 3,\n",
            "            \"score\": 5.0,\n",
            "            \"predicted_score\": 3.706,\n",
            "            \"composite_score\": 4.92\n",
            "        },\n",
            "        {\n",
            "            \"id\": \"03-102\",\n",
            "            \"category_id\": 3,\n",
            "            \"score\": 5.0,\n",
            "            \"predicted_score\": 3.833,\n",
            "            \"composite_score\": 4.92\n",
            "        },\n",
            "        {\n",
            "            \"id\": \"03-82\",\n",
            "            \"category_id\": 3,\n",
            "            \"score\": 5.0,\n",
            "            \"predicted_score\": 3.782,\n",
            "            \"composite_score\": 4.918\n",
            "        },\n",
            "        {\n",
            "            \"id\": \"03-172\",\n",
            "            \"category_id\": 3,\n",
            "            \"score\": 4.9,\n",
            "            \"predicted_score\": 3.976,\n",
            "            \"composite_score\": 4.916\n",
            "        },\n",
            "        {\n",
            "            \"id\": \"03-21\",\n",
            "            \"category_id\": 3,\n",
            "            \"score\": 4.9,\n",
            "            \"predicted_score\": 4.044,\n",
            "            \"composite_score\": 4.914\n",
            "        },\n",
            "        {\n",
            "            \"id\": \"03-132\",\n",
            "            \"category_id\": 3,\n",
            "            \"score\": 5.0,\n",
            "            \"predicted_score\": 3.79,\n",
            "            \"composite_score\": 4.898\n",
            "        },\n",
            "        {\n",
            "            \"id\": \"03-27\",\n",
            "            \"category_id\": 3,\n",
            "            \"score\": 4.8,\n",
            "            \"predicted_score\": 3.76,\n",
            "            \"composite_score\": 4.889\n",
            "        },\n",
            "        {\n",
            "            \"id\": \"03-111\",\n",
            "            \"category_id\": 3,\n",
            "            \"score\": 5.0,\n",
            "            \"predicted_score\": 3.808,\n",
            "            \"composite_score\": 4.889\n",
            "        },\n",
            "        {\n",
            "            \"id\": \"10-37\",\n",
            "            \"category_id\": 10,\n",
            "            \"score\": 5.0,\n",
            "            \"predicted_score\": 3.957,\n",
            "            \"composite_score\": 4.886\n",
            "        },\n",
            "        {\n",
            "            \"id\": \"11-21\",\n",
            "            \"category_id\": 11,\n",
            "            \"score\": 5.0,\n",
            "            \"predicted_score\": 3.716,\n",
            "            \"composite_score\": 4.88\n",
            "        },\n",
            "        {\n",
            "            \"id\": \"03-108\",\n",
            "            \"category_id\": 3,\n",
            "            \"score\": 5.0,\n",
            "            \"predicted_score\": 3.794,\n",
            "            \"composite_score\": 4.871\n",
            "        },\n",
            "        {\n",
            "            \"id\": \"10-67\",\n",
            "            \"category_id\": 10,\n",
            "            \"score\": 5.0,\n",
            "            \"predicted_score\": 3.744,\n",
            "            \"composite_score\": 4.871\n",
            "        },\n",
            "        {\n",
            "            \"id\": \"03-96\",\n",
            "            \"category_id\": 3,\n",
            "            \"score\": 5.0,\n",
            "            \"predicted_score\": 3.899,\n",
            "            \"composite_score\": 4.868\n",
            "        },\n",
            "        {\n",
            "            \"id\": \"03-17\",\n",
            "            \"category_id\": 3,\n",
            "            \"score\": 5.0,\n",
            "            \"predicted_score\": 3.991,\n",
            "            \"composite_score\": 4.864\n",
            "        },\n",
            "        {\n",
            "            \"id\": \"03-110\",\n",
            "            \"category_id\": 3,\n",
            "            \"score\": 5.0,\n",
            "            \"predicted_score\": 4.037,\n",
            "            \"composite_score\": 4.859\n",
            "        }\n",
            "    ]\n",
            "}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_f79255ee-008f-4875-9b8d-c07fa78d97d6\", \"recommendations_top15.json\", 2743)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 각 카테고리별 상위 5개 식당의 점수 구성요소 확인\n",
        "for cat_id in [0, 1, 6]:  # 중식, 일식, 한식\n",
        "    print(f\"\\n카테고리 {cat_id}의 상위 5개 식당 상세 분석:\")\n",
        "    cat_data = data_filtered[data_filtered['category_id'] == cat_id].sort_values('composite_score', ascending=False).head(5)\n",
        "\n",
        "    for idx, row in cat_data.iterrows():\n",
        "        # 각 구성요소 계산\n",
        "        base = row['final_score']\n",
        "        review_val = float(row['review'])\n",
        "        review_adjust = review_weight * np.log(review_val + 1)\n",
        "\n",
        "        pos = row.get('caution_배달가능', 0) + row.get('caution_예약가능', 0) + row.get('caution_포장가능', 0)\n",
        "        neg = row.get('caution_배달불가', 0) + row.get('caution_예약불가', 0) + row.get('caution_포장불가', 0)\n",
        "        caution_adjust = caution_weight * (pos - neg)\n",
        "\n",
        "        conv_cols = [col for col in row.index if col.startswith(\"conv_\")]\n",
        "        conv_mean = np.mean([row[col] for col in conv_cols]) if conv_cols else 0\n",
        "        conv_adjust = convenience_weight * conv_mean\n",
        "\n",
        "        print(f\"\\n식당 ID {idx}:\")\n",
        "        print(f\"기본 점수: {base:.3f}\")\n",
        "        print(f\"리뷰 수: {review_val:.0f}\")\n",
        "        print(f\"리뷰 보정: {review_adjust:.3f}\")\n",
        "        print(f\"유의사항 보정: {caution_adjust:.3f}\")\n",
        "        print(f\"편의시설 보정: {conv_adjust:.3f}\")\n",
        "        print(f\"최종 composite_score: {row['composite_score']:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vem4nlPZ_ctM",
        "outputId": "15f4d40e-e240-4c42-fe75-d87b8279111a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "카테고리 0의 상위 5개 식당 상세 분석:\n",
            "\n",
            "카테고리 1의 상위 5개 식당 상세 분석:\n",
            "\n",
            "식당 ID 207:\n",
            "기본 점수: 5.000\n",
            "리뷰 수: 3\n",
            "리뷰 보정: 0.555\n",
            "유의사항 보정: 0.300\n",
            "편의시설 보정: 0.150\n",
            "최종 composite_score: 4.908\n",
            "\n",
            "식당 ID 73:\n",
            "기본 점수: 5.000\n",
            "리뷰 수: 1\n",
            "리뷰 보정: 0.277\n",
            "유의사항 보정: 0.300\n",
            "편의시설 보정: 0.000\n",
            "최종 composite_score: 4.889\n",
            "\n",
            "식당 ID 192:\n",
            "기본 점수: 5.000\n",
            "리뷰 수: 14\n",
            "리뷰 보정: 1.083\n",
            "유의사항 보정: 0.150\n",
            "편의시설 보정: 0.075\n",
            "최종 composite_score: 4.880\n",
            "\n",
            "식당 ID 151:\n",
            "기본 점수: 4.800\n",
            "리뷰 수: 142\n",
            "리뷰 보정: 1.985\n",
            "유의사항 보정: 0.300\n",
            "편의시설 보정: 0.025\n",
            "최종 composite_score: 4.875\n",
            "\n",
            "식당 ID 184:\n",
            "기본 점수: 4.700\n",
            "리뷰 수: 1\n",
            "리뷰 보정: 0.277\n",
            "유의사항 보정: 0.450\n",
            "편의시설 보정: 0.025\n",
            "최종 composite_score: 4.871\n",
            "\n",
            "카테고리 6의 상위 5개 식당 상세 분석:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "predicted_score는 모델이 예측한 평점(또는 imputation을 통해 보완된 평점)입니다.\n",
        "composite_score는 이 예측 평점에 리뷰, 유의사항, 편의시설 등의 보정 값을 반영하여 계산한 최종 추천 평점입니다."
      ],
      "metadata": {
        "id": "wLcNEEk-wYt7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "만약 실제 평점이 없는 경우 imputation을 통해 가상 평점(보완된 평점)을 산출하고, 이 가상 평점을 기반으로 모델이 예측한 predicted_score를 계산하게 됩니다.\n",
        "즉, 데이터에 실제 평점이 없으면, imputation을 통해 보완된 가상 평점이 모델 입력의 기준이 되어 predicted_score가 산출됩니다"
      ],
      "metadata": {
        "id": "SDf0An_UwvhD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "결과값 컬럼\n",
        "\n",
        "- category_id: 식당의 카테고리를 나타내는 숫자형 값입니다.\n",
        "예를 들어, \"한식\", \"중식\", \"일식\" 등 미리 정의한 매핑에 따라 각 식당이 어느 카테고리에 속하는지를 보여줍니다.\n",
        "\n",
        "- score: 데이터에 존재하는 실제 평점 값(또는 imputation을 통해 보완된 평점)입니다.\n",
        "이 값은 식당이 원래 받은 평점을 의미하며, 대부분 상위 추천 식당에서는 4.7~5.0 정도의 높은 평점을 보입니다.\n",
        "\n",
        "- predicted_score: 모델(예: Stacking 앙상블 등)이 예측한 평점 값입니다.\n",
        "실제 평점과는 다르게 산출되며, 모델이 학습한 피처들을 기반으로 예측한 결과입니다.\n",
        "이 값은 모델의 예측 성능을 평가할 때 참고할 수 있으며, 보정 전의 예측치를 나타냅니다.\n",
        "\n",
        "- composite_score: 최종 추천 점수로, 실제 평점(score)에 리뷰에 대한 보정(예: 로그 변환된 review 값에 기초한 가중치 조정)과 유의사항(caution) 보정을 더한 값입니다.\n",
        "이 값은 최종적으로 추천 순위를 결정하는 데 사용됩니다.\n",
        "추가로, 전체 composite_score가 선형 스케일링을 통해 최대 5점으로 조정되었으므로, 이 값이 5점을 넘지 않게 되어 있습니다.\n"
      ],
      "metadata": {
        "id": "3IS0CSDtmApi"
      }
    }
  ]
}